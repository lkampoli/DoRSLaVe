{
 "cells": [
  {
   "cell_type": "raw",
   "id": "7b777c2f",
   "metadata": {},
   "source": [
    "---\n",
    "title: Optimisation\n",
    "include-in-header:\n",
    "  text: <script defer src=\"https://pyscript.net/latest/pyscript.js\"></script>\n",
    "resources: \"minimise-with-gradients.py\"\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "873e9211",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-05 16:26:02.634188: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/intel/oneapi/tbb/2021.12/env/../lib/intel64/gcc4.8:/opt/intel/oneapi/mpi/2021.12/opt/mpi/libfabric/lib:/opt/intel/oneapi/mpi/2021.12/lib:/opt/intel/oneapi/mkl/2024.1/lib:/opt/intel/oneapi/dpl/2022.5/lib:/opt/intel/oneapi/debugger/2024.1/opt/debugger/lib:/opt/intel/oneapi/compiler/2024.1/opt/oclfpga/host/linux64/lib:/opt/intel/oneapi/compiler/2024.1/opt/compiler/lib:/opt/intel/oneapi/compiler/2024.1/lib:/home/unimelb.edu.au/lcampoli/Downloads/tcl8.6.12-src/install/lib:/home/unimelb.edu.au/lcampoli/OpenFOAM/ThirdParty-7/platforms/linux64Gcc/gperftools-svn/lib:/home/unimelb.edu.au/lcampoli/OpenFOAM/lcampoli-7/platforms/linux64GccDPInt32Opt/lib:/home/unimelb.edu.au/lcampoli/OpenFOAM/site/7/platforms/linux64GccDPInt32Opt/lib:/home/unimelb.edu.au/lcampoli/OpenFOAM/OpenFOAM-7/platforms/linux64GccDPInt32Opt/lib:/home/unimelb.edu.au/lcampoli/OpenFOAM/ThirdParty-7/platforms/linux64GccDPInt32/lib:/home/unimelb.edu.au/lcampoli/OpenFOAM/OpenFOAM-7/platforms/linux64GccDPInt32Opt/lib/dummy:/home/unimelb.edu.au/lcampoli/CFD/UnDiFi-2D/petsc-3.14.6/arch-linux-c-debug/lib/:/home/unimelb.edu.au/lcampoli/Downloads/UnDiFi-2D/petsc-3.14.6/arch-linux-c-debug/lib/:/usr/lib/x86_64-linux-gnu/openmpi/lib/\n",
      "2024-09-05 16:26:02.634272: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'typeDict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 51>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m numpy\u001b[38;5;241m.\u001b[39mset_printoptions(precision\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     49\u001b[0m numpy\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m123\u001b[39m)\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\n\u001b[1;32m     53\u001b[0m tensorflow\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mset_seed(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     54\u001b[0m tensorflow\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mset_visible_devices([], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPU\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/__init__.py:37\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_typing\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyLoader \u001b[38;5;28;01mas\u001b[39;00m _LazyLoader\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/__init__.py:45\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# from tensorflow.python import keras\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_column\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m feature_column_lib \u001b[38;5;28;01mas\u001b[39;00m feature_column\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# from tensorflow.python.layers import layers\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodule\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/feature_column/feature_column_lib.py:18\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"FeatureColumns: tools for ingesting and representing features.\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-import,line-too-long,wildcard-import,g-bad-import-order\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_column\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_column\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_column\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_column_v2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_column\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequence_feature_column\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/feature_column/feature_column.py:143\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sparse_tensor \u001b[38;5;28;01mas\u001b[39;00m sparse_tensor_lib\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor_shape\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m array_ops\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_ops\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/layers/base.py:16\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# =============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Contains the base Layer class, from which all layers inherit.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy_tf_layers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base\n\u001b[1;32m     18\u001b[0m InputSpec \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mInputSpec\n\u001b[1;32m     20\u001b[0m keras_style_scope \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mkeras_style_scope\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/__init__.py:25\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# See b/110718070#comment18 for more details about this import.\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequential\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/models.py:22\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metrics \u001b[38;5;28;01mas\u001b[39;00m metrics_module\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optimizer_v1\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m functional\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sequential\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m training\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py:32\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m input_spec\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m node \u001b[38;5;28;01mas\u001b[39;00m node_module\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m training \u001b[38;5;28;01mas\u001b[39;00m training_lib\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m training_utils\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaved_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m network_serialization\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:52\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmixed_precision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m loss_scale_optimizer \u001b[38;5;28;01mas\u001b[39;00m lso\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmixed_precision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m policy\n\u001b[0;32m---> 52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hdf5_format\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m save\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m saving_utils\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/saving/hdf5_format.py:37\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 37\u001b[0m   \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mh5py\u001b[39;00m\n\u001b[1;32m     38\u001b[0m   HDF5_OBJECT_HEADER_LIMIT \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64512\u001b[39m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/h5py/__init__.py:46\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m     _warn((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh5py is running against HDF5 \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m when it was built against \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     38\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthis may cause problems\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     39\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;241m*\u001b[39mversion\u001b[38;5;241m.\u001b[39mhdf5_version_tuple),\n\u001b[1;32m     40\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;241m*\u001b[39mversion\u001b[38;5;241m.\u001b[39mhdf5_built_version_tuple)\n\u001b[1;32m     41\u001b[0m     ))\n\u001b[1;32m     44\u001b[0m _errors\u001b[38;5;241m.\u001b[39msilence_errors()\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_conv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m register_converters \u001b[38;5;28;01mas\u001b[39;00m _register_converters\n\u001b[1;32m     47\u001b[0m _register_converters()\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mh5z\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _register_lzf\n",
      "File \u001b[0;32mh5py/_conv.pyx:1\u001b[0m, in \u001b[0;36minit h5py._conv\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5t.pyx:293\u001b[0m, in \u001b[0;36minit h5py.h5t\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/numpy/__init__.py:320\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tester\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Tester\n\u001b[0;32m--> 320\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;18m__name__\u001b[39m, attr))\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'typeDict'"
     ]
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| warning: false\n",
    "import matplotlib\n",
    "from matplotlib  import pyplot as plt\n",
    "\n",
    "import cycler\n",
    "\n",
    "colors = [\"#91CCCC\", \"#FF8FA9\", \"#CC91BC\", \"#3F9999\", \"#A5FFB8\"]\n",
    "matplotlib.pyplot.rcParams[\"axes.prop_cycle\"] = cycler.cycler(color=colors)\n",
    "\n",
    "\n",
    "def set_square_figures():\n",
    "    matplotlib.pyplot.rcParams[\"figure.figsize\"] = (2.0, 2.0)\n",
    "\n",
    "\n",
    "def set_rectangular_figures():\n",
    "    matplotlib.pyplot.rcParams[\"figure.figsize\"] = (5.0, 2.0)\n",
    "\n",
    "\n",
    "set_rectangular_figures()\n",
    "matplotlib.pyplot.rcParams[\"figure.dpi\"] = 350\n",
    "matplotlib.pyplot.rcParams[\"savefig.bbox\"] = \"tight\"\n",
    "matplotlib.pyplot.rcParams[\"font.family\"] = \"serif\"\n",
    "\n",
    "matplotlib.pyplot.rcParams[\"axes.spines.right\"] = False\n",
    "matplotlib.pyplot.rcParams[\"axes.spines.top\"] = False\n",
    "\n",
    "\n",
    "def squareFig():\n",
    "    return matplotlib.pyplot.figure(figsize=(2, 2), dpi=350).gca()\n",
    "\n",
    "\n",
    "def add_diagonal_line():\n",
    "    xl = matplotlib.pyplot.xlim()\n",
    "    yl = matplotlib.pyplot.ylim()\n",
    "    shortestSide = min(xl[1], yl[1])\n",
    "    matplotlib.pyplot.plot(\n",
    "        [0, shortestSide], [0, shortestSide], color=\"black\", linestyle=\"--\"\n",
    "    )\n",
    "\n",
    "\n",
    "import pandas\n",
    "\n",
    "pandas.options.display.max_rows = 6\n",
    "\n",
    "import numpy\n",
    "\n",
    "numpy.set_printoptions(precision=2)\n",
    "numpy.random.seed(123)\n",
    "\n",
    "import tensorflow\n",
    "\n",
    "tensorflow.random.set_seed(1)\n",
    "tensorflow.config.set_visible_devices([], \"GPU\")\n",
    "\n",
    "\n",
    "def skip_empty(line):\n",
    "    if line.strip() != \"\":\n",
    "        print(line.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09a49fe",
   "metadata": {},
   "source": [
    "::: {.content-visible unless-format=\"revealjs\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8de588",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: Show the package imports\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341b614f",
   "metadata": {},
   "source": [
    ":::\n",
    "\n",
    "\n",
    "# Dense Layers in Matrices {data-visibility=\"uncounted\"}\n",
    "\n",
    "## Logistic regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1779d787",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "set_square_figures()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529b1adc",
   "metadata": {},
   "source": [
    "::: columns\n",
    "::: column\n",
    "\n",
    "Observations: $\\mathbf{x}_{i,\\bullet} \\in \\mathbb{R}^{2}$.\n",
    "\n",
    "Target: $y_i \\in \\{0, 1\\}$.\n",
    "\n",
    "Predict: $\\hat{y}_i = \\mathbb{P}(Y_i = 1)$.\n",
    "\n",
    "<br>\n",
    "\n",
    "__The model__\n",
    "\n",
    "For $\\mathbf{x}_{i,\\bullet} = (x_{i,1}, x_{i,2})$:\n",
    "$$\n",
    "z_i = x_{i,1} w_1 + x_{i,2} w_2 + b\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{y}_i = \\sigma(z_i) = \\frac{1}{1 + \\mathrm{e}^{-z_i}} .\n",
    "$$\n",
    "\n",
    ":::\n",
    "::: column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce64afcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy\n",
    "#sympy.plot(\"1/(1 + exp(-z))\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5871b6ea",
   "metadata": {},
   "source": [
    ":::\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb62ff34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "set_rectangular_figures()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6b39d2",
   "metadata": {},
   "source": [
    "## Multiple observations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38c7701",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"x_1\": [1, 3, 5], \"x_2\": [2, 4, 6], \"y\": [0, 1, 1]})\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b435946",
   "metadata": {},
   "source": [
    "Let $w_1 = 1$, $w_2 = 2$ and $b = -10$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ec328a",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_1 = 1; w_2 = 2; b = -10\n",
    "data[\"x_1\"] * w_1 + data[\"x_2\"] * w_2 + b "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ea1045",
   "metadata": {},
   "source": [
    "## Matrix notation\n",
    "\n",
    "::: columns\n",
    "::: column\n",
    "Have $\\mathbf{X} \\in \\mathbb{R}^{3 \\times 2}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819580f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = data[[\"x_1\", \"x_2\"]]\n",
    "X = X_df.to_numpy()\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b7404d",
   "metadata": {},
   "source": [
    ":::\n",
    "::: column\n",
    "Let $\\mathbf{w} = (w_1, w_2)^\\top \\in \\mathbb{R}^{2 \\times 1}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8e7af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.array([[1], [2]])\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ad17ef",
   "metadata": {},
   "source": [
    ":::\n",
    ":::\n",
    "\n",
    "$$\n",
    "\\mathbf{z} = \\mathbf{X} \\mathbf{w} + b , \\quad \\mathbf{a} = \\sigma(\\mathbf{z})\n",
    "$$\n",
    "\n",
    "::: columns\n",
    "::: column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512142f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = X.dot(w) + b\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae83959",
   "metadata": {},
   "source": [
    ":::\n",
    "::: column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bb4d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a269f83",
   "metadata": {},
   "source": [
    ":::\n",
    ":::\n",
    "\n",
    "## Using a softmax output\n",
    "\n",
    "::: columns\n",
    "::: column\n",
    "Observations: $\\mathbf{x}_{i,\\bullet} \\in \\mathbb{R}^{2}$.\n",
    "Predict: $\\hat{y}_{i,j} = \\mathbb{P}(Y_i = j)$.\n",
    ":::\n",
    "::: column\n",
    "Target: $\\mathbf{y}_{i,\\bullet} \\in \\{(1, 0), (0, 1)\\}$.\n",
    ":::\n",
    ":::\n",
    "\n",
    "__The model__: For $\\mathbf{x}_{i,\\bullet} = (x_{i,1}, x_{i,2})$\n",
    "$$\n",
    "\\begin{aligned}\n",
    "z_{i,1} &= x_{i,1} w_{1,1} + x_{i,2} w_{2,1} + b_1 , \\\\\n",
    "z_{i,2} &= x_{i,1} w_{1,2} + x_{i,2} w_{2,2} + b_2 .\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\hat{y}_{i,1} &= \\text{Softmax}_1(\\mathbf{z}_i) = \\frac{\\mathrm{e}^{z_{i,1}}}{\\mathrm{e}^{z_{i,1}} + \\mathrm{e}^{z_{i,2}}} , \\\\\n",
    "\\hat{y}_{i,2} &= \\text{Softmax}_2(\\mathbf{z}_i) = \\frac{\\mathrm{e}^{z_{i,2}}}{\\mathrm{e}^{z_{i,1}} + \\mathrm{e}^{z_{i,2}}} .\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "## Multiple observations\n",
    "\n",
    "::: columns\n",
    "::: column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bef4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "data = pd.DataFrame({\n",
    "  \"x_1\": [1, 3, 5], \"x_2\": [2, 4, 6],\n",
    "  \"y_1\": [1, 0, 0], \"y_2\": [0, 1, 1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d428bc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03a142c",
   "metadata": {},
   "source": [
    ":::\n",
    "::: column\n",
    "Choose:\n",
    "\n",
    "$w_{1,1} = 1$, $w_{2,1} = 2$,\n",
    "\n",
    "$w_{1,2} = 3$, $w_{2,2} = 4$, and\n",
    "\n",
    "$b_1 = -10$, $b_2 = -20$.\n",
    "\n",
    ":::\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaff85c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_11 = 1; w_21 = 2; b_1 = -10\n",
    "w_12 = 3; w_22 = 4; b_2 = -20\n",
    "data[\"x_1\"] * w_11 + data[\"x_2\"] * w_21 + b_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410ad83d",
   "metadata": {},
   "source": [
    "## Matrix notation\n",
    "\n",
    "::: columns\n",
    "::: column\n",
    "Have $\\mathbf{X} \\in \\mathbb{R}^{3 \\times 2}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77b41ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d28f69",
   "metadata": {},
   "source": [
    ":::\n",
    "::: column\n",
    "$\\mathbf{W}\\in \\mathbb{R}^{2\\times2}$, $\\mathbf{b}\\in \\mathbb{R}^{2}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8522bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.array([[1, 3], [2, 4]])\n",
    "b = np.array([-10, -20])\n",
    "display(W); b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c97fcb",
   "metadata": {},
   "source": [
    ":::\n",
    ":::\n",
    "\n",
    "$$\n",
    "  \\mathbf{Z} = \\mathbf{X} \\mathbf{W} + \\mathbf{b} , \\quad \\mathbf{A} = \\text{Softmax}(\\mathbf{Z}) .\n",
    "$$\n",
    "\n",
    "::: columns\n",
    "::: column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29177f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = X @ W + b\n",
    "Z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93253ec5",
   "metadata": {},
   "source": [
    ":::\n",
    "::: column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f9faac",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(Z) / np.sum(np.exp(Z),\n",
    "  axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecec6c93",
   "metadata": {},
   "source": [
    ":::\n",
    ":::\n",
    "\n",
    "\n",
    "\n",
    "# Optimisation {data-visibility=\"uncounted\"}\n",
    "\n",
    "## Gradient-based learning\n",
    "\n",
    "\n",
    "\n",
    "```{=html}\n",
    "<div style=\"font-size: 0px;\">\n",
    "  <py-config>packages = [\"matplotlib\"]</py-config>\n",
    "  </div>\n",
    "<div>\n",
    "  <!-- Source for slider with current value shown: https://stackoverflow.com/a/18936328 -->\n",
    "  Make a guess: <input type=\"range\" min=\"1\" max=\"100\" value=\"50\" class=\"slider\" id=\"new_guess\" oninput=\"this.nextElementSibling.value = this.value\">\n",
    "  <output>50</output><br>\n",
    "  Show derivatives: <input type=\"checkbox\" id=\"derivs\">\n",
    "  Reveal function: <input type=\"checkbox\" id=\"reveal\">\n",
    "</div>\n",
    "<div id=\"mpl\" style=\"text-align: center;\"></div>\n",
    "<py-script output=\"mpl\" src=\"minimise-with-gradients.py\" />\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "## Gradient descent pitfalls\n",
    "\n",
    "![Potential problems with gradient descent.](Geron-mls2_0406.png)\n",
    "\n",
    "::: footer\n",
    "Source: Aurélien Géron (2019), _Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow_, 2nd Edition, Figure 4-6.\n",
    ":::\n",
    "\n",
    "## Go over all the training data\n",
    "\n",
    "<br>\n",
    "\n",
    "Called _batch gradient descent_.\n",
    "\n",
    "<br>\n",
    "\n",
    "```python\n",
    "for i in range(num_epochs):\n",
    "    gradient = evaluate_gradient(loss_function, data, weights)\n",
    "    weights = weights - learning_rate * gradient\n",
    "```\n",
    "\n",
    "## Pick a random training example\n",
    "\n",
    "<br>\n",
    "\n",
    "Called _stochastic gradient descent_.\n",
    "\n",
    "<br>\n",
    "\n",
    "```python\n",
    "for i in range(num_epochs):\n",
    "    rnd.shuffle(data)\n",
    "    for example in data:\n",
    "        gradient = evaluate_gradient(loss_function, example, weights)\n",
    "        weights = weights - learning_rate * gradient\n",
    "```\n",
    "\n",
    "## Take a group of training examples\n",
    "\n",
    "<br>\n",
    "\n",
    "Called _mini-batch gradient descent_.\n",
    "\n",
    "<br>\n",
    "\n",
    "```python\n",
    "for i in range(num_epochs):\n",
    "    rnd.shuffle(data)\n",
    "    for b in range(num_batches):\n",
    "        batch = data[b * batch_size : (b + 1) * batch_size]\n",
    "        gradient = evaluate_gradient(loss_function, batch, weights)\n",
    "        weights = weights - learning_rate * gradient\n",
    "```\n",
    "\n",
    "## Mini-batch gradient descent\n",
    "\n",
    "::: columns\n",
    "::: column\n",
    "\n",
    "Why?\n",
    "\n",
    "1. Because we have to (data is too big)\n",
    "2. Because it is faster (lots of quick noisy steps > a few slow super accurate steps)\n",
    "3. The noise helps us jump out of local minima\n",
    "\n",
    ":::\n",
    "::: column\n",
    "![Example of jumping from local minima.](Geron-mls2_0406.png)\n",
    ":::\n",
    ":::\n",
    "\n",
    "::: footer\n",
    "Source: Aurélien Géron (2019), _Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow_, 2nd Edition, Figure 4-6.\n",
    ":::\n",
    "\n",
    "## Learning rates\n",
    "\n",
    "::: columns\n",
    "::: column\n",
    "\n",
    "![The learning rate is too small](Geron-mls2_0404.png)\n",
    ":::\n",
    "::: column\n",
    "![The learning rate is too large](Geron-mls2_0405.png)\n",
    ":::\n",
    ":::\n",
    "\n",
    "::: footer\n",
    "Source: Aurélien Géron (2019), _Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow_, 2nd Edition, Figures 4-4 and 4-5.\n",
    ":::\n",
    "\n",
    "## Learning rates #2\n",
    "\n",
    "![Changing the learning rates for a robot arm.](matt-henderson-learning-rates-animation.mov){width=60%}\n",
    "\n",
    "::: {.content-visible unless-format=\"revealjs\"}\n",
    "\n",
    "> \"a nice way to see how the learning rate affects Stochastic Gradient Descent.\n",
    "> we can use SGD to control a robot arm - minimizing the distance to the target as a function of the angles θᵢ. Too low a learning rate gives slow inefficient learning, too high and we see instability\"\n",
    "\n",
    ":::\n",
    "\n",
    "::: footer\n",
    "Source: Matt Henderson (2021), [Twitter post](https://twitter.com/matthen2/status/1520427516997025792)\n",
    ":::\n",
    "\n",
    "## Learning rate schedule\n",
    "\n",
    "![Learning curves for various learning rates η](Geron-mls2_1108.png)\n",
    "\n",
    "In training the learning rate may be tweaked manually.\n",
    "\n",
    "::: footer\n",
    "Source: Aurélien Géron (2019), _Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow_, 2nd Edition, Figure 11-8.\n",
    ":::\n",
    "\n",
    "## We need non-zero derivatives {.smaller}\n",
    "\n",
    "This is why can't use accuracy as the loss function for classification.\n",
    "\n",
    "Also why we can have the _dead ReLU_ problem.\n",
    "\n",
    "::: {.content-hidden unless-format=\"revealjs\"}\n",
    "\n",
    "\n",
    "{{< video https://www.youtube.com/embed/KpKog-L9veg width=\"100%\" height=\"80%\" >}}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ":::\n",
    "::: {.content-visible unless-format=\"revealjs\"}\n",
    "\n",
    "\n",
    "{{< video https://www.youtube.com/embed/KpKog-L9veg >}}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ":::\n",
    "\n",
    "# Loss and derivatives {data-visibility=\"uncounted\"}\n",
    "\n",
    "## Example: linear regression\n",
    "\n",
    "$$\n",
    "\\hat{y}(x) = w x + b\n",
    "$$\n",
    "\n",
    "For some observation $\\{ x_i, y_i \\}$, the (MSE) loss is\n",
    "\n",
    "$$ \n",
    "\\text{Loss}_i = (\\hat{y}(x_i) - y_i)^2\n",
    "$$\n",
    "\n",
    "For a batch of the first $n$ observations the loss is\n",
    "\n",
    "$$ \n",
    "\\text{Loss}_{1:n} = \\frac{1}{n} \\sum_{i=1}^n (\\hat{y}(x_i) - y_i)^2\n",
    "$$\n",
    "\n",
    "## Derivatives\n",
    "\n",
    "Since $\\hat{y}(x) = w x + b$,\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\hat{y}(x)}{\\partial w} = x \\text{ and }\n",
    "\\frac{\\partial \\hat{y}(x)}{\\partial b} = 1 .\n",
    "$$\n",
    "\n",
    "As $\\text{Loss}_i = (\\hat{y}(x_i) - y_i)^2$, we know\n",
    "$$\n",
    "\\frac{\\partial \\text{Loss}_i}{\\partial \\hat{y}(x_i) } = 2 (\\hat{y}(x_i) - y_i) .\n",
    "$$\n",
    "\n",
    "## Chain rule\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\text{Loss}_i}{\\partial \\hat{y}(x_i) } = 2 (\\hat{y}(x_i) - y_i), \\,\\,\n",
    "\\frac{\\partial \\hat{y}(x)}{\\partial w} = x , \\, \\text{ and } \\,\n",
    "\\frac{\\partial \\hat{y}(x)}{\\partial b} = 1 .\n",
    "$$\n",
    "\n",
    "Putting this together, we have\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\text{Loss}_i}{\\partial w}\n",
    "= \\frac{\\partial \\text{Loss}_i}{\\partial \\hat{y}(x_i) }\n",
    "  \\times \\frac{\\partial \\hat{y}(x_i)}{\\partial w}\n",
    "= 2 (\\hat{y}(x_i) - y_i) \\, x_i \n",
    "$$\n",
    "\n",
    "and\n",
    "$$\n",
    "\\frac{\\partial \\text{Loss}_i}{\\partial b}\n",
    "= \\frac{\\partial \\text{Loss}_i}{\\partial \\hat{y}(x_i) }\n",
    "  \\times \\frac{\\partial \\hat{y}(x_i)}{\\partial b}\n",
    "= 2 (\\hat{y}(x_i) - y_i) .\n",
    "$$\n",
    "\n",
    "## Stochastic gradient descent (SGD)\n",
    "\n",
    "Start with $\\boldsymbol{\\theta}_0 = (w, b)^\\top = (0, 0)^\\top$.\n",
    "\n",
    "Randomly pick $i=5$, say $x_i = 5$ and $y_i = 5$.\n",
    "\n",
    "::: fragment\n",
    "$$\n",
    "\\hat{y}(x_i) = 0 \\times 5 + 0 = 0 \\Rightarrow \\text{Loss}_i = (0 - 5)^2 = 25.\n",
    "$$\n",
    ":::\n",
    "::: fragment\n",
    "The partial derivatives are\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial \\text{Loss}_i}{\\partial w} \n",
    "&= 2 (\\hat{y}(x_i) - y_i) \\, x_i = 2 \\cdot (0 - 5) \\cdot 5 = -50, \\text{ and} \\\\\n",
    "\\frac{\\partial \\text{Loss}_i}{\\partial b}\n",
    "&= 2 (0 - 5) = - 10.\n",
    "\\end{aligned}\n",
    "$$\n",
    "The gradient is $\\nabla \\text{Loss}_i = (-50, -10)^\\top$.\n",
    ":::\n",
    "\n",
    "## SGD, first iteration\n",
    "\n",
    "Start with $\\boldsymbol{\\theta}_0 = (w, b)^\\top = (0, 0)^\\top$.\n",
    "\n",
    "Randomly pick $i=5$, say $x_i = 5$ and $y_i = 5$.\n",
    "\n",
    "The gradient is $\\nabla \\text{Loss}_i = (-50, -10)^\\top$.\n",
    "\n",
    "Use learning rate $\\eta = 0.01$ to update \n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\boldsymbol{\\theta}_1\n",
    "&= \\boldsymbol{\\theta}_0 - \\eta \\nabla \\text{Loss}_i \\\\\n",
    "&= \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} - 0.01 \\begin{pmatrix} -50 \\\\ -10 \\end{pmatrix} \\\\\n",
    "&= \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} + \\begin{pmatrix} 0.5 \\\\ 0.1 \\end{pmatrix} = \\begin{pmatrix} 0.5 \\\\ 0.1 \\end{pmatrix}.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "## SGD, second iteration\n",
    "\n",
    "Start with $\\boldsymbol{\\theta}_1 = (w, b)^\\top = (0.5, 0.1)^\\top$.\n",
    "\n",
    "Randomly pick $i=9$, say $x_i = 9$ and $y_i = 17$.\n",
    "\n",
    "The gradient is $\\nabla \\text{Loss}_i = (-223.2, -24.8)^\\top$.\n",
    "\n",
    "Use learning rate $\\eta = 0.01$ to update \n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\boldsymbol{\\theta}_2\n",
    "&= \\boldsymbol{\\theta}_1 - \\eta \\nabla \\text{Loss}_i \\\\\n",
    "&= \\begin{pmatrix} 0.5 \\\\ 0.1 \\end{pmatrix} - 0.01 \\begin{pmatrix} -223.2 \\\\ -24.8 \\end{pmatrix} \\\\\n",
    "&= \\begin{pmatrix} 0.5 \\\\ 0.1 \\end{pmatrix} + \\begin{pmatrix} 2.232 \\\\ 0.248 \\end{pmatrix} = \\begin{pmatrix} 2.732 \\\\ 0.348 \\end{pmatrix}.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "## Batch gradient descent (BGD) {.smaller}\n",
    "\n",
    "For the first $n$ observations \n",
    "$\\text{Loss}_{1:n} = \\frac{1}{n} \\sum_{i=1}^n \\text{Loss}_i$\n",
    "so\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial \\text{Loss}_{1:n}}{\\partial w}\n",
    "&= \\frac{1}{n} \\sum_{i=1}^n \\frac{\\partial \\text{Loss}_{i}}{\\partial w}\n",
    "= \\frac{1}{n} \\sum_{i=1}^n \\frac{\\partial \\text{Loss}_{i}}{\\hat{y}(x_i)} \\frac{\\partial \\hat{y}(x_i)}{\\partial w} \\\\\n",
    "&= \\frac{1}{n} \\sum_{i=1}^n 2 (\\hat{y}(x_i) - y_i) \\, x_i .\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial \\text{Loss}_{1:n}}{\\partial b}\n",
    "&= \\frac{1}{n} \\sum_{i=1}^n \\frac{\\partial \\text{Loss}_{i}}{\\partial b}\n",
    "= \\frac{1}{n} \\sum_{i=1}^n \\frac{\\partial \\text{Loss}_{i}}{\\hat{y}(x_i)} \\frac{\\partial \\hat{y}(x_i)}{\\partial b} \\\\\n",
    "&= \\frac{1}{n} \\sum_{i=1}^n 2 (\\hat{y}(x_i) - y_i) .\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "## BGD, first iteration ($\\boldsymbol{\\theta}_0 = \\boldsymbol{0}$) {.smaller}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fcef9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "numpy.random.seed(111)\n",
    "n = 3\n",
    "x = numpy.arange(1, n + 1)\n",
    "y = 2 * x - 1 + 0.01 * numpy.random.randn(n)\n",
    "\n",
    "theta_0 = numpy.array([0, 0])\n",
    "yhat = theta_0[0] * x + theta_0[1]\n",
    "\n",
    "loss = (yhat - y) ** 2\n",
    "\n",
    "dLossdw = 2 * (yhat - y) * x\n",
    "dLossdb = 2 * (yhat - y)\n",
    "\n",
    "df = pandas.DataFrame(\n",
    "    {\"x\": x, \"y\": y, \"y_hat\": yhat, \"loss\": loss, \"dL/dw\": dLossdw, \"dL/db\": dLossdb}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6335e3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "df.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430a72d0",
   "metadata": {},
   "source": [
    "So $\\nabla \\text{Loss}_{1:3}$ is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62e3451",
   "metadata": {},
   "outputs": [],
   "source": [
    "nabla = np.array([df[\"dL/dw\"].mean(), df[\"dL/db\"].mean()])\n",
    "nabla "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf109a7",
   "metadata": {},
   "source": [
    "so with $\\eta = 0.1$ then $\\boldsymbol{\\theta}_1$ becomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7b9147",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_1 = theta_0 - 0.1 * nabla\n",
    "theta_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1835db7",
   "metadata": {},
   "source": [
    "## BGD, second iteration {.smaller}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49786594",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "yhat = theta_1[0] * x + theta_1[1]\n",
    "loss = (yhat - y) ** 2\n",
    "dLossdw = 2 * (yhat - y) * x\n",
    "dLossdb = 2 * (yhat - y)\n",
    "\n",
    "df = pandas.DataFrame(\n",
    "    {\"x\": x, \"y\": y, \"y_hat\": yhat, \"loss\": loss, \"dL/dw\": dLossdw, \"dL/db\": dLossdb}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ccbf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "df.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4a32c3",
   "metadata": {},
   "source": [
    "So $\\nabla \\text{Loss}_{1:3}$ is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8d25b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nabla = np.array([df[\"dL/dw\"].mean(), df[\"dL/db\"].mean()])\n",
    "nabla "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48205179",
   "metadata": {},
   "source": [
    "so with $\\eta = 0.1$ then $\\boldsymbol{\\theta}_2$ becomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f488da",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_2 = theta_1 - 0.1 * nabla\n",
    "theta_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8ee649",
   "metadata": {},
   "source": [
    "## Glossary {.appendix data-visibility=\"uncounted\"}\n",
    "\n",
    "- batches, batch size\n",
    "- gradient-based learning, hill-climbing\n",
    "- stochastic (mini-batch) gradient descent"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
