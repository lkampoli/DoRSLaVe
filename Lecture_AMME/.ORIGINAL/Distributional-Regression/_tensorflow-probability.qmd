
## Tensorflow Probability

```{python}
#| echo: false
from pathlib import Path
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split
from sklearn.compose import make_column_transformer
from sklearn.preprocessing import MinMaxScaler

if Path("freq_data.csv").exists():
    freq = pd.read_csv("freq_data.csv")
else:
    freq = fetch_openml(data_id=41214, as_frame=True).frame
    freq.to_csv("freq_data.csv", index=False)

# Remove the column named 'IDpol'.
freq = freq.drop("IDpol", axis=1)

# Convert categorical variables to numeric.
freq = pd.get_dummies(freq, columns=["VehGas", "Area", "VehBrand", "Region"])

features = freq.drop("ClaimNb", axis=1)
target = freq["ClaimNb"]

X_main, X_test, y_main, y_test = train_test_split(features, target, random_state=2022)
X_train, X_val, y_train, y_val = train_test_split(X_main, y_main, random_state=2022)

ctsCols = ["Exposure", "VehPower", "VehAge", "DrivAge", "BonusMalus", "Density"]

ct = make_column_transformer(
  (MinMaxScaler(), ctsCols),
  remainder="passthrough"
)

X_train = ct.fit_transform(X_train)
X_val = ct.transform(X_val)
X_test = ct.transform(X_test)
```

```{python}
import tensorflow_probability as tfp
tfd = tfp.distributions
```

```{python}
random.seed(123)
model = keras.Sequential([
  layers.Dense(24, "leaky_relu", input_dim=X_train.shape[1]),
  layers.Dense(1, "exponential"),
  tfp.layers.DistributionLambda(tfd.Poisson)
])

def NLL(y_true, y_hat):
  return -y_hat.log_prob(y_true)

model.compile(loss=NLL)
model.fit(X_train, y_train, epochs=3, verbose=0);
```

:::{.callout-tip}
## Suggested viewing

Josh Dylan (2019), [TensorFlow Probability: Learning with confidence](https://youtu.be/BrwKURU-wpk), TF Dev Summit '19, YouTube (14 mins).
:::

## Predictions are then distributions

```{python}
y_pred = model(X_val)
type(y_pred)
```

```{python}
y_pred.mean()[:3]
```

```{python}
y_pred.stddev()[:3]
```


## Zero-inflated Poisson

```{python}
def zero_inf(out): 
  rate = tf.squeeze(tf.math.exp(out[:,0:1]))
  s = tf.math.sigmoid(out[:,1:2])
  probs = tf.concat([1-s, s], axis=1)
  return tfd.Mixture(
    cat=tfd.Categorical(probs=probs),
    components=[
      tfd.Deterministic(loc=tf.zeros_like(rate)),
      tfd.Poisson(rate=rate),
    ])
```

```{python}
random.seed(123)

zipModel = keras.Sequential([
  layers.Dense(24, "leaky_relu", input_dim=X_train.shape[1]),
  layers.Dense(2),
  tfp.layers.DistributionLambda(zero_inf)
])

def NLL(y_true, y_hat):
  return -y_hat.log_prob(y_true)

zipModel.compile(loss=NLL)
```

## Evaluations are then likelihoods

```{python}
zipModel.fit(X_train, y_train, epochs=3, verbose=0);
```

```{python}
model.evaluate(X_val, y_val, verbose=0)
```

```{python}
zipModel.evaluate(X_val, y_val, verbose=0)
```

:::{.smaller}
> In statistics, sometimes we only use a single data set. To still be able to evaluate the performance of the developed prediction model on the same data, sophisticated methods have developed over a long period of time and are still in use in some parts of the statistics community. These methods account for the fact that the model saw the data during fitting and applied corrections to account for that. These methods include, for example, the Akaike Information Criterion (AIC) or the Bayesian Information Criterion (BIC). Don’t get confused. If you have a validation set, you don’t need these methods.
:::

::: footer
Source: Sic & Duerr (2020), Probabilistic Deep Learning, Chapter 5.
:::
