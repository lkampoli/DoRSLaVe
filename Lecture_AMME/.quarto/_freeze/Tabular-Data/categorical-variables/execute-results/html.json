{
  "hash": "ae869fc537855370cf032f6e35fbc6c5",
  "result": {
    "markdown": "---\ntitle: Categorical Variables\n---\n\n\n\n::: {.content-visible unless-format=\"revealjs\"}\n\n::: {.cell execution_count=2}\n``` {.python .cell-code code-fold=\"true\" code-summary=\"Show the package imports\"}\nimport random\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.callbacks import EarlyStopping\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LinearRegression\n```\n:::\n\n\n:::\n\n# Preprocessing {visibility=\"uncounted\"}\n\n::: {.content-visible unless-format=\"revealjs\"}\nPreprocessing data is essential in creating a successful neural network. Proper preprocessing ensures the data is in a format conducive to learning. \n:::\n\n## Keras model methods\n\n\n\n::: columns\n::: {.column width=\"45%\"}\n- `compile`: specify the loss function and optimiser\n- `fit`: learn the parameters of the model\n- `predict`: apply the model\n- `evaluate`: apply the model and calculate a metric \n:::\n::: {.column width=\"55%\"}\n\n<br>\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nrandom.seed(12)\nmodel = Sequential()\nmodel.add(Dense(1, activation=\"relu\"))\nmodel.compile(\"adam\", \"poisson\")\nmodel.fit(X_train, y_train, verbose=0)\ny_pred = model.predict(X_val, verbose=0)\nprint(model.evaluate(X_val, y_val, verbose=0))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n4.944334506988525\n```\n:::\n:::\n\n\n:::\n:::\n\n## Scikit-learn model methods\n\n::: columns\n::: {.column width=\"45%\"}\n- `fit`: learn the parameters of the model\n- `predict`: apply the model\n- `score`: apply the model and calculate a metric \n:::\n::: {.column width=\"55%\"}\n\n<br>\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_val)\nprint(model.score(X_val, y_val))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n-0.6668505979514445\n```\n:::\n:::\n\n\n:::\n:::\n\n\n## Scikit-learn preprocessing methods\n\n::: columns\n::: {.column width=\"45%\"}\n- `fit`: learn the parameters of the transformation\n- `transform`: apply the transformation\n- `fit_transform`: learn the parameters and apply the transformation\n:::\n::: {.column width=\"55%\"}\n\n::: {.panel-tabset}\n\n### `fit`\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nscaler = StandardScaler()\nscaler.fit(X_train)\nX_train_sc = scaler.transform(X_train)\nX_val_sc = scaler.transform(X_val)\nX_test_sc = scaler.transform(X_test)\n\nprint(X_train_sc.mean(axis=0))\nprint(X_train_sc.std(axis=0))\nprint(X_val_sc.mean(axis=0))\nprint(X_val_sc.std(axis=0))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[ 2.97e-17 -1.39e-17  1.98e-17 -5.65e-17]\n[1. 1. 1. 1.]\n[-0.34  0.07 -0.27 -0.82]\n[1.01 0.66 1.26 0.89]\n```\n:::\n:::\n\n\n### `fit_transform`\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nscaler = StandardScaler()\nX_train_sc = scaler.fit_transform(X_train)\nX_val_sc = scaler.transform(X_val)\nX_test_sc = scaler.transform(X_test)\n\nprint(X_train_sc.mean(axis=0))\nprint(X_train_sc.std(axis=0))\nprint(X_val_sc.mean(axis=0))\nprint(X_val_sc.std(axis=0))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[ 2.97e-17 -1.39e-17  1.98e-17 -5.65e-17]\n[1. 1. 1. 1.]\n[-0.34  0.07 -0.27 -0.82]\n[1.01 0.66 1.26 0.89]\n```\n:::\n:::\n\n\n:::\n\n:::\n:::\n\n::: {.content-visible unless-format=\"revealjs\"}\nIt is important to make sure that the scaler is fitted using only the data from the train set.\n:::\n## Summary of the splitting\n\n![](Melantha_Wang_ML_workflow.svg)\n\n::: footer\nSource: Melantha Wang (2022), ACTL3143 Project.\n:::\n\n## Dataframes & arrays\n\n::: columns\n::: column\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nX_test.head(3)\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>x1</th>\n      <th>x2</th>\n      <th>x3</th>\n      <th>x4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>83</th>\n      <td>0.075805</td>\n      <td>-0.677162</td>\n      <td>0.975120</td>\n      <td>-0.147057</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>0.954002</td>\n      <td>0.651391</td>\n      <td>-0.315269</td>\n      <td>0.758969</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>0.113517</td>\n      <td>0.662131</td>\n      <td>1.586017</td>\n      <td>-1.237815</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n:::\n::: column\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nX_test_sc\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\narray([[ 0.13, -0.64,  0.89, -0.4 ],\n       [ 1.15,  0.67, -0.44,  0.62],\n       [ 0.18,  0.68,  1.52, -1.62],\n       [ 0.77, -0.82, -1.22,  0.31],\n       [ 0.06,  1.46, -0.39,  2.83],\n       [ 2.21,  0.49, -1.34,  0.51],\n       [-0.57,  0.53, -0.02,  0.86],\n       [ 0.16,  0.61, -0.96,  2.12],\n       [ 0.9 ,  0.2 , -0.23, -0.57],\n       [ 0.62, -0.11,  0.55,  1.48],\n       [ 0.  ,  1.57, -2.81,  0.69],\n       [ 0.96, -0.87,  1.33, -1.81],\n       [-0.64,  0.87,  0.25, -1.01],\n       [-1.19,  0.49, -1.06,  1.51],\n       [ 0.65,  1.54, -0.23,  0.22],\n       [-1.13,  0.34, -1.05, -1.82],\n       [ 0.02,  0.14,  1.2 , -0.9 ],\n       [ 0.68, -0.17, -0.34,  1.  ],\n       [ 0.44, -1.72,  0.22, -0.66],\n       [ 0.73,  2.19, -1.13, -0.87],\n       [ 2.73, -1.82,  0.59, -2.04],\n       [ 1.04, -0.13, -0.13, -1.36],\n       [-0.14,  0.43,  1.82, -0.04],\n       [-0.24, -0.72, -1.03, -1.15],\n       [ 0.28, -0.57, -0.04, -0.66]])\n```\n:::\n:::\n\n\n:::\n:::\n\n::: {.callout-note}\nBy default, when you pass `sklearn` a DataFrame it returns a `numpy` array.\n:::\n\n## Keep as a DataFrame\n\n::: columns\n::: {.column width=\"55%\"}\n\n<br>\n\nFrom [scikit-learn 1.2](https://scikit-learn.org/stable/auto_examples/release_highlights/plot_release_highlights_1_2_0.html#pandas-output-with-set-output-api):\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\nfrom sklearn import set_config              #<1>\nset_config(transform_output=\"pandas\")       #<2>\n\nimp = SimpleImputer()                       #<3>\nimp.fit(X_train)                            #<4>\nX_train_imp = imp.fit_transform(X_train)    #<5>\nX_val_imp = imp.transform(X_val)            #<6>\nX_test_imp = imp.transform(X_test)          #<7>\n```\n:::\n\n\n::: {.content-visible unless-format=\"revealjs\"}\n1. Imports `set_config` function from `sklearn`.\n2. Sets the configuration to transofrm the output back to pandas.\n3. Defines the `SimpleImputer`. This function helps in dealing with missing values. Default is set to `mean`, meaning that, missing values in each column will be replaced with the column mean.\n4. Applies `SimpleImputer` on the train set before applying the scaler.\n5. Fits and transforms the train set\n6. Transforms the validation set\n7. Transforms the test set\n:::\n:::\n::: {.column width=\"45%\"}\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\nX_test_imp\n```\n\n::: {.cell-output .cell-output-display execution_count=11}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>x1</th>\n      <th>x2</th>\n      <th>x3</th>\n      <th>x4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>83</th>\n      <td>0.075805</td>\n      <td>-0.677162</td>\n      <td>0.975120</td>\n      <td>-0.147057</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>0.954002</td>\n      <td>0.651391</td>\n      <td>-0.315269</td>\n      <td>0.758969</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>-0.245388</td>\n      <td>-0.753736</td>\n      <td>-0.889514</td>\n      <td>-0.815810</td>\n    </tr>\n    <tr>\n      <th>69</th>\n      <td>0.199060</td>\n      <td>-0.600217</td>\n      <td>0.069802</td>\n      <td>-0.385314</td>\n    </tr>\n  </tbody>\n</table>\n<p>25 rows Ã— 4 columns</p>\n</div>\n```\n:::\n:::\n\n\n:::\n:::\n\n\n\n# French Motor Claims Dataset {visibility=\"uncounted\"}\n\n## French motor dataset\n\nDownload the dataset if we don't have it already.\n\n::: {.cell output-location='slide' execution_count=13}\n``` {.python .cell-code}\nfrom pathlib import Path                                      #<1>\nfrom sklearn.datasets import fetch_openml                     #<2>\n\nif not Path(\"french-motor.csv\").exists():                     #<3>\n    freq = fetch_openml(data_id=41214, as_frame=True).frame   #<4>\n    freq.to_csv(\"french-motor.csv\", index=False)              #<5>\nelse:\n    freq = pd.read_csv(\"french-motor.csv\")                    #<6>\n\nfreq\n```\n\n::: {.cell-output .cell-output-display execution_count=13}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>IDpol</th>\n      <th>ClaimNb</th>\n      <th>Exposure</th>\n      <th>Area</th>\n      <th>VehPower</th>\n      <th>VehAge</th>\n      <th>DrivAge</th>\n      <th>BonusMalus</th>\n      <th>VehBrand</th>\n      <th>VehGas</th>\n      <th>Density</th>\n      <th>Region</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0.10000</td>\n      <td>D</td>\n      <td>5</td>\n      <td>0</td>\n      <td>55</td>\n      <td>50</td>\n      <td>B12</td>\n      <td>'Regular'</td>\n      <td>1217</td>\n      <td>R82</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3.0</td>\n      <td>1</td>\n      <td>0.77000</td>\n      <td>D</td>\n      <td>5</td>\n      <td>0</td>\n      <td>55</td>\n      <td>50</td>\n      <td>B12</td>\n      <td>'Regular'</td>\n      <td>1217</td>\n      <td>R82</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5.0</td>\n      <td>1</td>\n      <td>0.75000</td>\n      <td>B</td>\n      <td>6</td>\n      <td>2</td>\n      <td>52</td>\n      <td>50</td>\n      <td>B12</td>\n      <td>'Diesel'</td>\n      <td>54</td>\n      <td>R22</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>678010</th>\n      <td>6114328.0</td>\n      <td>0</td>\n      <td>0.00274</td>\n      <td>D</td>\n      <td>6</td>\n      <td>2</td>\n      <td>45</td>\n      <td>50</td>\n      <td>B12</td>\n      <td>'Diesel'</td>\n      <td>1323</td>\n      <td>R82</td>\n    </tr>\n    <tr>\n      <th>678011</th>\n      <td>6114329.0</td>\n      <td>0</td>\n      <td>0.00274</td>\n      <td>B</td>\n      <td>4</td>\n      <td>0</td>\n      <td>60</td>\n      <td>50</td>\n      <td>B12</td>\n      <td>'Regular'</td>\n      <td>95</td>\n      <td>R26</td>\n    </tr>\n    <tr>\n      <th>678012</th>\n      <td>6114330.0</td>\n      <td>0</td>\n      <td>0.00274</td>\n      <td>B</td>\n      <td>7</td>\n      <td>6</td>\n      <td>29</td>\n      <td>54</td>\n      <td>B12</td>\n      <td>'Diesel'</td>\n      <td>65</td>\n      <td>R72</td>\n    </tr>\n  </tbody>\n</table>\n<p>678013 rows Ã— 12 columns</p>\n</div>\n```\n:::\n:::\n\n\n::: {.content-visible unless-format=\"revealjs\"}\n1. Imports `Path` class from the `pathlib`. \n2. Imports the `fetch_openml` function from the `sklearn.datasets` module. `fetch_openml` allows the user to bring in the datasets available in the OpenML platform. Every dataset has a unique ID, hence, can be fetched by providing the ID. `data_id` of the French motor dataset is 41214. \n3. Checks if the dataset does not already exist with in the Jupyter Notebook directory. \n4. Fetches the dataset from OpenML \n5. Convers the dataset into `.csv` format\n6. If it already exists, then read the dataset as a `.csv` file\n:::\n\n## Data dictionary {.smaller}\n\n::: columns\n::: column\n- `IDpol`: policy number (unique identifier)\n- `ClaimNb`: number of claims on the given policy\n- `Exposure`: total exposure in yearly units\n- `Area`: area code (categorical, ordinal)\n- `VehPower`: power of the car (categorical, ordinal)\n- `VehAge`: age of the car in years\n- `DrivAge`: age of the (most common) driver in years\n:::\n::: column\n- `BonusMalus`: bonus-malus level between 50 and 230 (with reference level 100)\n- `VehBrand`: car brand (categorical, nominal)\n- `VehGas`: diesel or regular fuel car (binary)\n- `Density`: density of inhabitants per km^2^ in the city of the living place of the driver\n- `Region`: regions in France (prior to 2016)\n:::\n:::\n\n::: footer\nSource: Nell et al. (2020), [Case Study: French Motor Third-Party Liability Claims](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3164764), SSRN.\n:::\n\n## The model\n\nHave $\\{ (\\mathbf{x}_i, y_i) \\}_{i=1, \\dots, n}$ for $\\mathbf{x}_i \\in \\mathbb{R}^{47}$ and $y_i \\in \\mathbb{N}_0$.\n\nAssume the distribution\n$$\nY_i \\sim \\mathsf{Poisson}(\\lambda(\\mathbf{x}_i))\n$$\n\nWe have $\\mathbb{E} Y_i = \\lambda(\\mathbf{x}_i)$. \nThe NN takes $\\mathbf{x}_i$ & predicts $\\mathbb{E} Y_i$.\n\n# Ordinal Variables {visibility=\"uncounted\"}\n\n## Subsample and split\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\nfreq = freq.drop(\"IDpol\", axis=1).head(25_000)                          #<1>\n\nX_train, X_test, y_train, y_test = train_test_split(                    #<2>\n  freq.drop(\"ClaimNb\", axis=1), freq[\"ClaimNb\"], random_state=2023)     #<2>\n\n# Reset each index to start at 0 again.\nX_train = X_train.reset_index(drop=True)                                #<3>\nX_test = X_test.reset_index(drop=True)                                  #<3>\n```\n:::\n\n\n::: {.content-visible unless-format=\"revealjs\"}\n1. Drops the `\"IDpol\"` column and selects only the top 25_000 rows of the dataset\n2. Splits the dataset in to train and test sets. By setting the `random_state` to a specific number, we ensure the consistency in the train-test split. `freq.drop(\"ClaimNb\", axis=1)` removes the \"ClaimNb\" column.\n3. Resets the index of train set, and drops the previous index column. Since the index column will get shuffled during the train-test split, we may want to reset the index to start from 0 again. \n:::\n\n## What values do we see in the data?\n\n::: {layout-ncol=2 layout-nrow=2}\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\nX_train[\"Area\"].value_counts()\n```\n\n::: {.cell-output .cell-output-display execution_count=15}\n```\nArea\nC    5507\nD    4113\nA    3527\nE    2769\nB    2359\nF     475\nName: count, dtype: int64\n```\n:::\n:::\n\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\nX_train[\"VehBrand\"].value_counts()\n```\n\n::: {.cell-output .cell-output-display execution_count=16}\n```\nVehBrand\nB1     5069\nB2     4838\nB12    3708\n       ... \nB13     336\nB11     284\nB14     136\nName: count, Length: 11, dtype: int64\n```\n:::\n:::\n\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\nX_train[\"VehGas\"].value_counts()\n```\n\n::: {.cell-output .cell-output-display execution_count=17}\n```\nVehGas\n'Regular'    10773\n'Diesel'      7977\nName: count, dtype: int64\n```\n:::\n:::\n\n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\nX_train[\"Region\"].value_counts()\n```\n\n::: {.cell-output .cell-output-display execution_count=18}\n```\nRegion\nR24    6498\nR82    2119\nR11    1909\n       ... \nR21      90\nR42      55\nR43      26\nName: count, Length: 22, dtype: int64\n```\n:::\n:::\n\n\n:::\n\n::: {.content-visible unless-format=\"revealjs\"}\n`data[\"column_name\"].value_counts()` function provides counts of each category for a categorical variable. In this dataset, variables `Area` and `VehGas` are assumed to have natural orderings whereas `VehBrand` and `Region` are not considered to have such natural orderings. Therefore, the two sets of categorical variables will have to be treated differently.\n:::\n\n## Ordinal & binary categories are easy\n\n::: {.cell execution_count=19}\n``` {.python .cell-code}\nfrom sklearn.preprocessing import OrdinalEncoder              #<1>\noe = OrdinalEncoder()                                         #<2>\noe.fit(X_train[[\"Area\", \"VehGas\"]])                           #<3>\noe.categories_                                                #<4>\n```\n\n::: {.cell-output .cell-output-display execution_count=19}\n```\n[array(['A', 'B', 'C', 'D', 'E', 'F'], dtype=object),\n array([\"'Diesel'\", \"'Regular'\"], dtype=object)]\n```\n:::\n:::\n\n\n::: {.content-visible unless-format=\"revealjs\"}\n`OrdinalEncoder` can assign numerical values to each category of the ordinal variable. The nice thing about `OrdinalEncoder` is that it can preserve the information about ordinal relationships in the data. Furthermore, this encoding is more efficient in terms of memory usage. \n1. Imports the `OrdinalEncoder` from `sklearn.preprocessing` library\n2. Defines the `OrdinalEncoder` object as `oe`\n3. Selects the two columns with ordinal variables from `X_train` and fits the ordinal encoder\n4. Gives out the number of unique categories in each ordinal variable\n:::\n\n::: {.cell execution_count=20}\n``` {.python .cell-code}\nfor i, area in enumerate(oe.categories_[0]):\n    print(f\"The Area value {area} gets turned into {i}.\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThe Area value A gets turned into 0.\nThe Area value B gets turned into 1.\nThe Area value C gets turned into 2.\nThe Area value D gets turned into 3.\nThe Area value E gets turned into 4.\nThe Area value F gets turned into 5.\n```\n:::\n:::\n\n\n::: {.cell execution_count=21}\n``` {.python .cell-code}\nfor i, gas in enumerate(oe.categories_[1]):\n    print(f\"The VehGas value {gas} gets turned into {i}.\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThe VehGas value 'Diesel' gets turned into 0.\nThe VehGas value 'Regular' gets turned into 1.\n```\n:::\n:::\n\n\n## Ordinal encoded values\n\n::: {.content-visible unless-format=\"revealjs\"}\nNote that fitting an ordinal encoder (`oe.fit`) only establishes the mapping between numerical values and ordinal variable levels. To actually convert the values in the ordinal columns, we must also apply the `oe.transform` function. Following lines of code shows how we consistently apply the transform function to both train and test sets. To avoid inconsistencies in encoding, we use `oe.fit` function only to the train set.\n:::\n\n::: {.cell execution_count=22}\n``` {.python .cell-code}\nX_train_ord = oe.transform(X_train[[\"Area\", \"VehGas\"]])\nX_test_ord = oe.transform(X_test[[\"Area\", \"VehGas\"]])\n```\n:::\n\n\n::: columns\n::: column\n\n::: {.cell execution_count=23}\n``` {.python .cell-code}\nX_train[[\"Area\", \"VehGas\"]].head()\n```\n\n::: {.cell-output .cell-output-display execution_count=23}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Area</th>\n      <th>VehGas</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>C</td>\n      <td>'Diesel'</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>C</td>\n      <td>'Regular'</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>E</td>\n      <td>'Regular'</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>D</td>\n      <td>'Diesel'</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A</td>\n      <td>'Regular'</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n:::\n::: column\n\n::: {.cell execution_count=24}\n``` {.python .cell-code}\nX_train_ord.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=24}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Area</th>\n      <th>VehGas</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n:::\n:::\n\n## Train on ordinal encoded values\n\n::: {.content-visible unless-format=\"revealjs\"}\nIf we would like to see whether we can train a neural network only on the ordinal variables, we can try the following code.\n:::\n\n::: {.cell execution_count=25}\n``` {.python .cell-code}\nrandom.seed(12)                                                 #<1>\nmodel = Sequential([                                            #<2>\n  Dense(1, activation=\"exponential\")\n])\n\nmodel.compile(optimizer=\"adam\", loss=\"poisson\")                 #<3>\n\nes = EarlyStopping(verbose=True)                                #<4>\nhist = model.fit(X_train_ord, y_train, epochs=100, verbose=0,   #<5>\n    validation_split=0.2, callbacks=[es])\nhist.history[\"val_loss\"][-1]                                    #<6>\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nEpoch 22: early stopping\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=25}\n```\n0.7821308970451355\n```\n:::\n:::\n\n\n::: {.content-visible unless-format=\"revealjs\"}\n1. Sets the random state for reproducibility\n2. Constructs a neural network with 1 `Dense` layer, 1 neuron and an exponential activation function\n3. Compiles the model by defining the optimizer and loss function\n4. Defines the early stopping object (Note that the early stopping object only works if we have a validation set. If we do not define a validation set, there will be no validation loss, hence, no metric to compare the training loss with.)\n5. Fits the model only with the encoded columns as input data. The command `validation_split=0.2` tells the neural network to treat the last 20% of input data as the validation set. This is an alternative way of defining the validation set. \n6. Returns the validation loss at the final epoch of training\n:::\n\n<br>\n\nWhat about adding the continuous variables back in?\nUse a sklearn _column transformer_ for that.\n\n## Preprocess ordinal & continuous\n\n::: {.cell execution_count=26}\n``` {.python .cell-code}\nfrom sklearn.compose import make_column_transformer         #<1>\n\nct = make_column_transformer(                               #<2>\n  (OrdinalEncoder(), [\"Area\", \"VehGas\"]),                   #<3>\n  (\"drop\", [\"VehBrand\", \"Region\"]),                         #<4>\n  remainder=StandardScaler()                                #<5>\n)\n\nX_train_ct = ct.fit_transform(X_train)                      #<6>\n```\n:::\n\n\n::: {.content-visible unless-format=\"revealjs\"}\n1. Imports the `make_column_transformer` class that can carry out data preparation selectively\n2. Starts defining the column transformer object \n3. Selects the ordinal columns and apply ordinal encoding \n4. Drops the nominal columns\n5. Applies  `StandardScaler` transformation to the remaining numerical columns\n6. Fits and transforms the train set using the defined column transformer object\n:::\n\n::: columns\n::: column\n\n::: {.cell execution_count=27}\n``` {.python .cell-code}\nX_train.head(3)\n```\n\n::: {.cell-output .cell-output-display execution_count=27}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Exposure</th>\n      <th>Area</th>\n      <th>VehPower</th>\n      <th>VehAge</th>\n      <th>DrivAge</th>\n      <th>BonusMalus</th>\n      <th>VehBrand</th>\n      <th>VehGas</th>\n      <th>Density</th>\n      <th>Region</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.00</td>\n      <td>C</td>\n      <td>6</td>\n      <td>2</td>\n      <td>66</td>\n      <td>50</td>\n      <td>B2</td>\n      <td>'Diesel'</td>\n      <td>124</td>\n      <td>R24</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.36</td>\n      <td>C</td>\n      <td>4</td>\n      <td>10</td>\n      <td>22</td>\n      <td>100</td>\n      <td>B1</td>\n      <td>'Regular'</td>\n      <td>377</td>\n      <td>R93</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.02</td>\n      <td>E</td>\n      <td>12</td>\n      <td>8</td>\n      <td>44</td>\n      <td>60</td>\n      <td>B3</td>\n      <td>'Regular'</td>\n      <td>5628</td>\n      <td>R11</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n:::\n::: column\n\n::: {.cell execution_count=28}\n``` {.python .cell-code}\nX_train_ct.head(3)\n```\n\n::: {.cell-output .cell-output-display execution_count=28}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ordinalencoder__Area</th>\n      <th>ordinalencoder__VehGas</th>\n      <th>remainder__Exposure</th>\n      <th>remainder__VehPower</th>\n      <th>remainder__VehAge</th>\n      <th>remainder__DrivAge</th>\n      <th>remainder__BonusMalus</th>\n      <th>remainder__Density</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>1.126979</td>\n      <td>-0.165005</td>\n      <td>-0.844589</td>\n      <td>1.451036</td>\n      <td>-0.637179</td>\n      <td>-0.366980</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>-0.590896</td>\n      <td>-1.228181</td>\n      <td>0.586255</td>\n      <td>-1.548692</td>\n      <td>2.303010</td>\n      <td>-0.302700</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>-1.503517</td>\n      <td>3.024524</td>\n      <td>0.228544</td>\n      <td>-0.048828</td>\n      <td>-0.049141</td>\n      <td>1.031432</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n:::\n:::\n::: {.content-visible unless-format=\"revealjs\"}\n`X_train_ct.head(3)` returns a dataset with column names replaced according to a strange setting. To avoid that, we can use the `verbose_feature_names_out=False` command. Following code shows how the command results in a better looking `X_train_ct` data set. \n:::\n## Preprocess ordinal & continuous II\n\n::: {.cell execution_count=29}\n``` {.python .cell-code}\nfrom sklearn.compose import make_column_transformer\n\nct = make_column_transformer(\n  (OrdinalEncoder(), [\"Area\", \"VehGas\"]),\n  (\"drop\", [\"VehBrand\", \"Region\"]),\n  remainder=StandardScaler(),\n  verbose_feature_names_out=False\n)\nX_train_ct = ct.fit_transform(X_train)\n```\n:::\n\n\n::: columns\n::: column\n\n::: {.cell execution_count=30}\n``` {.python .cell-code}\nX_train.head(3)\n```\n\n::: {.cell-output .cell-output-display execution_count=30}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Exposure</th>\n      <th>Area</th>\n      <th>VehPower</th>\n      <th>VehAge</th>\n      <th>DrivAge</th>\n      <th>BonusMalus</th>\n      <th>VehBrand</th>\n      <th>VehGas</th>\n      <th>Density</th>\n      <th>Region</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.00</td>\n      <td>C</td>\n      <td>6</td>\n      <td>2</td>\n      <td>66</td>\n      <td>50</td>\n      <td>B2</td>\n      <td>'Diesel'</td>\n      <td>124</td>\n      <td>R24</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.36</td>\n      <td>C</td>\n      <td>4</td>\n      <td>10</td>\n      <td>22</td>\n      <td>100</td>\n      <td>B1</td>\n      <td>'Regular'</td>\n      <td>377</td>\n      <td>R93</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.02</td>\n      <td>E</td>\n      <td>12</td>\n      <td>8</td>\n      <td>44</td>\n      <td>60</td>\n      <td>B3</td>\n      <td>'Regular'</td>\n      <td>5628</td>\n      <td>R11</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n:::\n::: column\n\n::: {.cell execution_count=31}\n``` {.python .cell-code}\nX_train_ct.head(3)\n```\n\n::: {.cell-output .cell-output-display execution_count=31}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Area</th>\n      <th>VehGas</th>\n      <th>Exposure</th>\n      <th>VehPower</th>\n      <th>VehAge</th>\n      <th>DrivAge</th>\n      <th>BonusMalus</th>\n      <th>Density</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>1.126979</td>\n      <td>-0.165005</td>\n      <td>-0.844589</td>\n      <td>1.451036</td>\n      <td>-0.637179</td>\n      <td>-0.366980</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>-0.590896</td>\n      <td>-1.228181</td>\n      <td>0.586255</td>\n      <td>-1.548692</td>\n      <td>2.303010</td>\n      <td>-0.302700</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>-1.503517</td>\n      <td>3.024524</td>\n      <td>0.228544</td>\n      <td>-0.048828</td>\n      <td>-0.049141</td>\n      <td>1.031432</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n:::\n:::\n::: {.content-visible unless-format=\"revealjs\"}\nAn important thing to notice here is that, the order of columns have changed. They are rearranged according to the order in which we specify the transformations inside the column transformer. \n:::\n\n## Glossary {.appendix data-visibility=\"uncounted\"}\n\n- column transformer\n- nominal variables\n- ordinal variables\n\n",
    "supporting": [
      "categorical-variables_files/figure-revealjs"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}